{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d10944d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Paragraph = \"\"\"\n",
    "The Bank of England is the central bank of the United Kingdom and the model on which most modern central banks have been based. \n",
    "Established in 1694 to act as the English Government's banker and debt manager, and still one of the bankers for the government \n",
    "of the United Kingdom, it is the world's second oldest central bank.[3]\n",
    "\n",
    "The bank was privately owned by stockholders from its foundation in 1694 until it was nationalised in 1946 by the Attlee \n",
    "ministry.[4] In 1998 it became an independent public organisation, wholly owned by the Treasury Solicitor on behalf of the \n",
    "government,[5] with a mandate to support the economic policies of the government of the day,[6] but independence in maintaining \n",
    "price stability.[7] In the 21st century the bank took on increased responsibility for maintaining and monitoring financial \n",
    "stability in the UK, and it increasingly functions as a statutory regulator.[8]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d489134b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Bank of England is the central bank of the United Kingdom and the model on which most modern central banks have been based. Established in 1694 to act as the English Government's banker and debt manager, and still one of the bankers for the government of the United Kingdom, it is the world's second oldest central bank.[3]\n",
      "\n",
      "The bank was privately owned by stockholders from its foundation in 1694 until it was nationalised in 1946 by the Attlee ministry.[4] In 1998 it became an independent public organisation, wholly owned by the Treasury Solicitor on behalf of the government,[5] with a mandate to support the economic policies of the government of the day,[6] but independence in maintaining price stability.[7] In the 21st century the bank took on increased responsibility for maintaining and monitoring financial stability in the UK, and it increasingly functions as a statutory regulator.[8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(Paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f4ff14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d83d10ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3def028",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2d23509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize Sentences\n",
    "sentences = sent_tokenize(Paragraph)\n",
    "\n",
    "# Stopwords fallback\n",
    "try:\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "except:\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c9e99cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d83894c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Model (First 5 Rows):\n",
      "[[0 0 3 0 1 0 0 2 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [1 0 1 2 0 0 0 1 0 0 1 0 0 1 1 0 0 0 2 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0\n",
      "  0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1]\n",
      " [0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0\n",
      "  0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 2 0 0 2 0 1 0 1 0 0 0 0 0 0 0 1 1 1\n",
      "  1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      "  0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing text\n",
    "corpus = []\n",
    "for sentence in sentences:\n",
    "    review = re.sub(r'[^a-zA-Z]', ' ', sentence)  # Remove non-alphabetic characters\n",
    "    review = review.lower()  # Convert to lowercase\n",
    "    review = review.split()  # Tokenize words\n",
    "    \n",
    "    # Stemming\n",
    "    review = [ps.stem(word) for word in review if word not in stop_words]\n",
    "    \n",
    "    # Join words back into a single string\n",
    "    review = ' '.join(review)\n",
    "    \n",
    "    corpus.append(review)\n",
    "\n",
    "# Creating the Bag of Words (BoW) model\n",
    "cv = CountVectorizer(max_features=1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "\n",
    "# Print results\n",
    "print(\"Bag of Words Model (First 5 Rows):\")\n",
    "print(X[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36d4964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
